# config.yaml
urls:
  # URL for downloading data_submission
  data_url: "https://raw.githubusercontent.com/rewire-online/edos/main/data/edos_labelled_aggregated.csv"
  data_individual_annotations_url: "https://raw.githubusercontent.com/rewire-online/edos/main/data/edos_labelled_individual_annotations.csv'"

paths:
  # Relative input path for data_submission
  data_file: "../data_submission/edos_labelled_aggregated.parquet"
  data_file_csv: "../data_submission/edos_labelled_aggregated.csv"

  # Output directory path
  output_dir: "../data_submission"

  preprocessing_file: "milestone_1/run_preprocessing.py"

  dl_model_dir: "../milestone_2/model-finetuned_sexism-detection"
  dl_model_file: "milestone_2/run_dlmodel.py"
  dl_model_output: "dl_predictions.csv"

files:
  # Main output files within the output directory
  parquet_file: "full_dataset.parquet"
  conllu_file: "full_dataset.conllu"

  # Subsets for train, dev, and test splits
  subsets:
    train:
      parquet: "train_dataset.parquet"
      conllu: "train_dataset.conllu"
    dev:
      parquet: "dev_dataset.parquet"
      conllu: "dev_dataset.conllu"
    test:
      parquet: "test_dataset.parquet"
      conllu: "test_dataset.conllu"

dl_hyperparams:
  modelname_base: "martin-ha/toxic-comment-model"
  load_checkpoint: False
  checkpoint: "../milestone_2/model-finetuned_sexism-detection/checkpoint-1314"
  seed: 391832
  batch_size: 64
  train_epochs: 15
  early_stopping_epochs: 5
  eval_metric: "balanced_accuracy"

