# config.yaml
urls:
  # URL for downloading data_submission
  data_url: "https://raw.githubusercontent.com/rewire-online/edos/main/data/edos_labelled_aggregated.csv"
  data_individual_annotations_url: "https://raw.githubusercontent.com/rewire-online/edos/main/data/edos_labelled_individual_annotations.csv'"

paths:
  # Relative input path for data_submission
  data_file: "../data_submission/edos_labelled_aggregated.parquet"
  data_file_csv: "../data_submission/edos_labelled_aggregated.csv"

  # Output directory path
  output_dir: "../data_submission"

  preprocessing_file: "milestone_1/run_preprocessing.py"

  dl_model_dir: "../milestone_2/model-finetuned_sexism-detection"
  dl_model_file: "milestone_2/run_dlmodel.py"
  dl_model_output: "dl_predictions.csv"

  nb_model_dir: "../milestone_2/models/naivebayes"
  nb_model_file: "milestone_2/run_naivebayes.py"
  nb_model_output: "nb_predictions.csv"

  lr_model_dir: "../milestone_2/models/logistic_regression"
  svm_model_dir: "../milestone_2/models/svm"


files:
  # Main output files within the output directory
  parquet_file: "full_dataset.parquet"
  conllu_file: "full_dataset.conllu"

  # Subsets for train, dev, and test splits
  subsets:
    train:
      parquet: "train_dataset.parquet"
      conllu: "train_dataset.conllu"
    dev:
      parquet: "dev_dataset.parquet"
      conllu: "dev_dataset.conllu"
    test:
      parquet: "test_dataset.parquet"
      conllu: "test_dataset.conllu"

dl_hyperparams:
  modelname_base: "martin-ha/toxic-comment-model"
  load_checkpoint: False
  checkpoint: "../milestone_2/model-finetuned_sexism-detection/checkpoint-1314"
  seed: 391832
  batch_size: 64
  train_epochs: 15
  early_stopping_epochs: 5
  eval_metric: "balanced_accuracy"

nb_params:
  train: FALSE
  model_timestamp: "20241209_165351"
  feature_extraction: "tfidf"
  tfidf_params:
    max_features: 5000
    ngram_range: [1, 2]
    min_df: 5

lr_params1:
  train: true  # Set to true if you want to train the model
  model_timestamp: "20241209_165351"
  model_type: "tf-idf_logistic_regression" 
  feature_extraction: "tfidf"  
  tfidf_params:
    max_features: 5000
    ngram_range: [1, 2]
    min_df: 5
  logistic_params:
    max_iter: 500
    class_weight: "balanced"
  smote_params:  
    sampling_strategy: "auto"  
    k_neighbors: 5  
    random_state: 42  

lr_params2:
  train: true  
  model_timestamp: "20241209_165352"
  model_type: "word2vec_logistic_regression"  
  feature_extraction: "word2vec"
  logistic_params:
    max_iter: 500
    class_weight: "balanced"
  smote_params: 
    sampling_strategy: "auto"  
    k_neighbors: 5  
    random_state: 42

svm_params:
  random_state: 42
  class_weight: "balanced"
  probability: true
  kernel: "rbf"  # You can specify the kernel type (e.g., 'linear', 'poly', 'rbf', 'sigmoid')
  C: 1.0  # Regularization parameter
  gamma: "scale"  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'

smote_params:
  random_state: 42
  sampling_strategy: 'auto'
  k_neighbors: 5
  n_jobs: -1

